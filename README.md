# ğŸ§  Prompt-Regression-Automation

A lightweight automation agent designed to test, validate, and audit outputs from LLMs (e.g., Gemini, GPT) for hallucinations, reasoning drift, and structural inconsistencies â€” then log and report issues via email in near real-time.

---

## âš™ï¸ What It Does

- Runs a batch of prompts through an LLM (currently Gemini)
- Compares token-level output against expected structure or logic
- Detects regressions in reasoning, tone, structure, or factual content
- Automatically sends email alerts for flagged outputs

---

## ğŸ” Workflow

> Built using `n8n`, integrated with:
- **Gemini API** for prompt execution
- **Gmail** for auto-alerts
- **Telegram** for real-time notifications

graph TD;
    A[ğŸ•’ Schedule Trigger] --> B[ğŸ“„ Get Rows from Google Sheet];
    B --> C[âœï¸ Edit Fields (Preprocessing)];
    C --> D[ğŸ¤– Gemini Chat Model API];
    D --> E[ğŸ§  AI Agent: Internal Validation + Memory Tool];
    E --> F[âœï¸ Edit Fields (LLM Response Formatting)];
    F --> G[âœï¸ Edit Fields (Drift Detection Logic)];
    G --> H[âœï¸ Final Output Formatter];
    H --> I[ğŸ“Š Update Google Sheet];
    I --> J{â“ If: Is Drift Detected?};
    J -- true --> K[ğŸ§® Aggregate Alert Data];
    K --> L[ğŸ“§ Send Alert Email];


ğŸ§ª Key Features
âœ… Token-level comparison for logic or factual inconsistencies
ğŸ“¤ Auto-email alerts when drifts are detected
ğŸ”„ Extendable to support multiple LLM providers
ğŸ“ˆ Tracks regression over time to improve prompt quality

ğŸš€ Why This Matters
Manual testing of LLM responses is slow and error-prone. This agent:
Tested 10 prompts with 30+ points each in under 4 minutes
Reduced manual review time by 80%+
Supports iterative prompt refinement at scale

ğŸ› ï¸ Tech Stack
n8n
Gemini API (can be extended to OpenAI)
Gmail API
Telegram Bot API
